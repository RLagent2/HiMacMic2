#experiment info

name: "GRF-HiMacMic"


beta: 0.1
count_lmd: 0.3
batch_size_run: 1 #8


t_max: 8050000
runner: "episode"
counter_log_interval: 1000000
loss: "cross"
td_lambda2: 0.6
skip_dim: 4   #d
n_allgoals: 25
n_subgoals: 25
goal_dim: 25
#do not know parameters
td_lambda: 0.9
target_update_interval: 20
tsg_buffer_size: 100
lr: 0.0005 # Learning rate for agents
gamma: 0.999
size_run: 1
mini_batch: 4
r_baseline: 0.5
batch_size: 128
buffer_size: 5000
mixing_embed_dim: 32
hypernet_embed: 64

#non Adjusting parameters
success_sig: 1
hindsight: False
success_hindsight: True
count_lmd_e: 0.0 #not used
tsg_batch_size: 1 #add agent batch, add tsg train times,can not train more than one batch
tsg_sample_size: 20
add_goal_num: 0 #not used
add_goal: True #not used
reward_int: True
reward_positive: True #not used
x_range: 5.0
y_range: 5.0

# use epsilon greedy action selector
action_selector: "epsilon_greedy"
epsilon_start: 1.0
skip_epsilon_start: 1.0
epsilon_finish: 0.05
skip_epsilon_finish: 0.05
epsilon_anneal_time: 100000
skip_epsilon_anneal_time: 100000

obs_agent_id: False
obs_last_action: False
obs_individual_obs: False

x_length: 1.0
y_length: 0.84
keeper_x: 1.0
keeper_y: 0.0

# use Learner to train
tsg_mac: "ns_tsg_mac"
agent_mac: "agent_mac"
agent: "rnn"
tsg_agent: "tsg_ns_rnn"
agent_output_type: q
learner: "tsg_learner"
mixer: "tsg_qmix"
agent_mixer: "qmix"
optimizer: 'adam'
q_lambda: False
skip_hidden_dim: 30 #not use
use_cuda: False
double_q: False